library(tidyverse)
library(textdata)
library(tidytext)
library(quanteda)
library(tidyverse)
library(textdata)
library(tidytext)
install.packages("quanteda")
library(quanteda)
library(rio)
#import df
vas <- read.csv("article_df.csv")
View(vas)
#the vas df already has a tokenized sentence column.
vas <- vas |>
clean_names()
library(janitor)
library(striprtf)
library(tidyverse)
library(textdata)
library(tidytext)
#install.packages("quanteda")
library(quanteda)
library(rio)
library(janitor)
#the vas df already has a tokenized sentence column.
vas <- vas |>
clean_names()
vas_scent <- str_replace_all(vas$sentence, "- ", "")
vas_scent_df <- tibble(vas_scent,)
vas_tokenized <- vas_scent_df %>%
unnest_tokens(word,vas_scent)
vas_tokenized
View(vas_scent_df)
View(vas_tokenized)
View(vas_scent_df)
data(stop_words)
vas_tokenized <- vas_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
View(vas_tokenized)
# Word Count
word_ct <- vas_tokenized %>%
count(word, sort=TRUE)
word_ct
# cite this lexicon
#install.packages("textdata")
nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")
bing_word_counts %>%
group_by(sentiment) %>%
slice_max(n, n = 10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
library(tidytext)
get_sentiments("afinn")
library(tidytext)
load("../data/afinn.rda")
library(janeaustenr)
library(dplyr)
library(stringr)
tidy_books <- austen_books() %>%
group_by(book) %>%
mutate(
linenumber = row_number(),
chapter = cumsum(str_detect(text,
regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup() %>%
unnest_tokens(word, text)
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
nrc_joy <- get_sentiments("nrc") %>%
filter(sentiment == "joy")
tidy_books %>%
filter(book == "Emma") %>%
inner_join(nrc_joy) %>%
count(word, sort = TRUE)
library(tidyr)
jane_austen_sentiment <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative)
library(ggplot2)
ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
geom_col(show.legend = FALSE) +
facet_wrap(~book, ncol = 2, scales = "free_x")
afinn <- pride_prejudice %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
pride_prejudice <- tidy_books %>%
filter(book == "Pride & Prejudice")
pride_prejudice
afinn <- pride_prejudice %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
bing_and_nrc <- bind_rows(
pride_prejudice %>%
inner_join(get_sentiments("bing")) %>%
mutate(method = "Bing et al."),
pride_prejudice %>%
inner_join(get_sentiments("nrc") %>%
filter(sentiment %in% c("positive",
"negative"))) %>%
mutate(method = "NRC")) %>%
count(method, index = linenumber %/% 80, sentiment) %>%
pivot_wider(names_from = sentiment,
values_from = n,
values_fill = 0) %>%
mutate(sentiment = positive - negative)
bind_rows(afinn,
bing_and_nrc) %>%
ggplot(aes(index, sentiment, fill = method)) +
geom_col(show.legend = FALSE) +
facet_wrap(~method, ncol = 1, scales = "free_y")
get_sentiments("nrc") %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment)
nrc %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment)
get_sentiments("bing") %>%
count(sentiment)
bing_word_counts <- tidy_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
bing_word_counts
bing_word_counts %>%
group_by(sentiment) %>%
slice_max(n, n = 10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(x = "Contribution to sentiment",
y = NULL)
nrc_counts <- vas_tokenized %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
nrc_counts
sentiments_all <- text_tokenized %>%
inner_join(nrc_sentiments)
sentiments_all <- vas_tokenized %>%
inner_join(nrc_sentiments)
View(sentiments_all)
View(nrc_sentiments)
get_sentiments("nrc") %>%
count(sentiment)
nrc_counts <- vas_tokenized %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
nrc_counts
nrc_sentiments.count(sentiment)
nrc_sentiments %>%
count(sentiment)
nrc_sentiments %>%
count(sentiment, sort = TRUE)
vas_tokenized %>%
inner_join(nrc_sentiments) %>%
count(sentiment) %>%
arrange(desc(n))
nrc_sentiments %>%
count(sentiment)
nrc_sentiments %>%
count(sentiment, sort = TRUE)
sentiments_all <- vas_tokenized %>%
inner_join(nrc_sentiments)
nrc_counts <- vas_tokenized %>%
inner_join(nrc_sentiments) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
nrc_counts
nrc_counts2 <- vas_tokenized %>%
inner_join(nrc_sentiments) %>%
filter(sentiment %in% c("positive", "negative"))%>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
nrc_counts
View(sentiments_all)
vas_tokenized %>%
inner_join(nrc_sentiments %>%
filter(sentiment %in% c("positive", "negative"))) %>%
count(sentiment) %>%
spread(sentiment, n) %>%
mutate(sentiment_score = positive - negative)
View(bing_and_nrc)
View(pride_prejudice)
nrc_counts <- vas_tokenized %>%
inner_join(nrc_sentiments) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
nrc_counts
overall_sentiment <- vas_tokenized %>%
filter(sentiment %in% c("positive", "negative")) %>%
count(sentiment)
overall_sentiment <- vas_tokenized %>%
inner_join(nrc_sentiments %>%
filter(sentiment %in% c("positive",
"negative"))) %>%
count(sentiment)
overall_sentiment <- vas_tokenized %>%
inner_join(nrc_sentiments %>%
filter(sentiment %in% c("positive",
"negative"))) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
overall_sentiment
#Count with only binary categories
overall_nrc_counts <- vas_tokenized %>%
inner_join(nrc_sentiments %>%
filter(sentiment %in% c("positive",
"negative"))) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
overall_nrc_counts
#Count with all sentiment categories
nrc_counts <- vas_tokenized %>%
inner_join(nrc_sentiments) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
nrc_counts
ggplot(nrc_counts, aes(x = reorder(sentiment, n), y = n, fill = nrc_sentiments)) +
geom_col() +
coord_flip() +
labs(title = "NRC Sentiment Analysis",
x = "NRC Sentiment",
y = "Count") +
theme_minimal()
View(nrc_counts)
View(nrc_counts)
ggplot(nrc_counts, aes(x = reorder(sentiment, n), y = n, fill = sentiment)) +
geom_col() +
coord_flip() +
labs(title = "NRC Sentiment Analysis",
x = "NRC Sentiment",
y = "Count") +
theme_minimal()
ggplot(nrc_counts, aes(x = reorder(sentiment, n), y = n, fill = sentiment)) +
geom_col() +
coord_flip() +
labs(title = "NRC Sentiment Analysis of vasectomy reportings",
x = "NRC Sentiment",
y = "Count") +
theme_minimal()
anger <- vas_tokenized %>%
filter(sentiment == "anger")
View(vas_tokenized)
View(nrc_counts)
vas_sentiments <- vas_tokenized %>%
inner_join(nrc_sentiments)
View(vas_sentiments)
View(vas_tokenized)
#Count with all sentiment categories
nrc_counts <- vas_sentiments %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
nrc_counts
#Count with only binary categories
overall_nrc_counts <- vas_tokenized %>%
inner_join(nrc_sentiments %>%
filter(sentiment %in% c("positive",
"negative"))) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
overall_nrc_counts
anger <- vas_sentiments %>%
filter(sentiment == "anger")
anger
library(tidyverse)
library(textdata)
library(tidytext)
#install.packages("quanteda")
library(quanteda)
library(rio)
library(janitor)
#import df
vas <- read.csv("article_df.csv")
#the vas df already has a sentence column.
vas <- vas |>
clean_names()
vas_scent <- str_replace_all(vas$sentence, "- ", "")
vas_scent_df <- tibble(vas_scent,)
vas_tokenized <- vas_scent_df %>%
unnest_tokens(word,vas_scent)
vas_tokenized
#remove stop words
data(stop_words)
vas_tokenized <- vas_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
# Word Count
word_ct <- vas_tokenized %>%
count(word, sort=TRUE)
word_ct
# cite this lexicon
#install.packages("textdata")
nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")
nrc_sentiments %>%
count(sentiment, sort = TRUE)
vas_sentiments <- vas_tokenized %>%
inner_join(nrc_sentiments)
#Count with all sentiment categories
nrc_counts <- vas_sentiments %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
nrc_counts
#Count with only binary categories
overall_nrc_counts <- vas_tokenized %>%
inner_join(nrc_sentiments %>%
filter(sentiment %in% c("positive",
"negative"))) %>%
count(word, sentiment, sort = TRUE) %>%
ungroup()
overall_nrc_counts
ggplot(nrc_counts, aes(x = reorder(sentiment, n), y = n, fill = sentiment)) +
geom_col() +
coord_flip() +
labs(title = "NRC Sentiment Analysis of vasectomy reportings",
x = "NRC Sentiment",
y = "Count") +
theme_minimal()
anger <- vas_sentiments %>%
filter(sentiment == "anger")
anger
