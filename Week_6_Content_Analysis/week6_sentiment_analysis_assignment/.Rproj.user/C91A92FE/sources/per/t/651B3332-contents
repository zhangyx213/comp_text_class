---
title: "zhang_week6_sentiment_analysis_assignment"
author: "Catherine Zhang"
date: "2025-03-08"
output: html_document
---

# Jour689 Spring 2025

For this exercise, you will use your project file dataframe to conduct a basic sentiment analysis of your articles


Step #1: load the following libraries: tidyverse, textdata, tidytext, quanteda, rio

```{r}
library(tidyverse)
library(textdata)
library(tidytext)
#install.packages("quanteda")
library(quanteda)
library(rio)
library(janitor)
```


#import your "articles_df.csv" that contains the text of all of your articles in one dataframe. This is the spreadsheet we created last week in the "Text Compiler-Bigrams" exercise. 
```{r}
#import df 
vas <- read.csv("article_df.csv")
```

#Tokenize sentence into a df, remove stopwords


```{r}

#the vas df already has a sentence column.

vas <- vas |> 
  clean_names()

vas_scent <- str_replace_all(vas$sentence, "- ", "")
vas_scent_df <- tibble(vas_scent,)

vas_tokenized <- vas_scent_df %>%
  unnest_tokens(word,vas_scent)

vas_tokenized

#remove stop words

data(stop_words)

vas_tokenized <- vas_tokenized %>%
  anti_join(stop_words, by = c("word" = "word")) %>%
  filter(word != "temp_file") %>%
  filter(word != "stories_corpus") %>%
  filter(!grepl('[0-9]', word))

```


# Count the words in descending order
```{r}
# Word Count
word_ct <- vas_tokenized %>%
  count(word, sort=TRUE)

word_ct

```

# NRC Sentiment

NRC Lexicon on Whole Corpus
"The nrc lexicon categorizes words in a binary fashion (“yes”/“no”) into categories of positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust."
```{r}
# cite this lexicon
#install.packages("textdata")
nrc_sentiments <- get_sentiments("nrc")
afinn_sentiments <- get_sentiments("afinn")
```

#Count the NRC sentiments
```{r}

nrc_sentiments %>% 
  count(sentiment, sort = TRUE)

```

### Join the NRC Sentiments with the tokenized data


```{r}

vas_sentiments <- vas_tokenized %>%
  inner_join(nrc_sentiments) 

```

### Count Overall Sentiment with NRC

```{r}
#Count with all sentiment categories
nrc_counts <- vas_sentiments %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

nrc_counts

```


```{r}
#Count with only binary categories
overall_nrc_counts <- vas_tokenized %>%
  inner_join(nrc_sentiments %>% 
                 filter(sentiment %in% c("positive", 
                                         "negative"))) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

overall_nrc_counts

```

## Use ggplot to chart Sentiments with the tokenized data

```{r}
ggplot(nrc_counts, aes(x = reorder(sentiment, n), y = n, fill = sentiment)) +
  geom_col() +
  coord_flip() +
  labs(title = "NRC Sentiment Analysis of vasectomy reportings",
       x = "NRC Sentiment",
       y = "Count") +
  theme_minimal()

```



# Create a new dataframe just with the NRC "anger" sentiment
```{r}
anger <- vas_sentiments %>%
  filter(sentiment == "anger")

anger
```

