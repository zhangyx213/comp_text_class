"0","textdata2 <- vascn2 %>% "
"0","  select(filename, sentence, year) %>% "
"0","  as.data.frame() %>% "
"0","  rename(doc_id = filename, text= sentence)"
"0",""
"0","# load stopwords"
"0","english_stopwords <- readLines(""https://slcladal.github.io/resources/stopwords_en.txt"", encoding = ""UTF-8"")"
"0",""
"0","custom_stop_wordscn <- bind_rows("
"0","  tibble(word = c(""China"", ""date"", ""english"", ""language"", ""china"", ""copyright"", "
"0","                  ""end"", ""document"", ""word"", ""length"",""kong"",""hong"",""year"",""south"",""morning"",""post"",""news"",""reserve"",""xinhua""),"
"0","         lexicon = rep(""custom"", 19)), "
"0","  stop_words"
"0",")"
"0","# create corpus object"
"0","corpuscn <- Corpus(DataframeSource(textdata2))"
"0","# Preprocessing chain"
"0","processedCorpuscn <- tm_map(corpuscn, content_transformer(tolower))"
"0","processedCorpuscn <- tm_map(processedCorpuscn, removeWords, english_stopwords)"
"0","processedCorpuscn <- tm_map(processedCorpuscn, removePunctuation, preserve_intra_word_dashes = TRUE)"
"0","processedCorpuscn <- tm_map(processedCorpuscn, removeNumbers) "
"0","processedCorpuscn <- tm_map(processedCorpuscn, stemDocument, language = ""en"")"
"0","processedCorpuscn <- tm_map(processedCorpuscn, stripWhitespace)"
"0","processedCorpuscn <- tm_map(processedCorpuscn, removeWords, custom_stop_wordscn$word) "
"0",""
