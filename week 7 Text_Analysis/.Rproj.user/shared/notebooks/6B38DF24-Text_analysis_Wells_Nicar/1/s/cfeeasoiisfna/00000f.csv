"0","#tokenize the headlines only"
"0","headline_sentiment <- combined_index |> "
"0","  select(filename, candidate, index) |>  "
"0","  mutate(text = str_replace_all(filename, ""_"", "" ""),"
"0","         text = str_replace_all(text, "".txt"", """")) |>    group_by(index, candidate) |> "
"0","  unnest_tokens(tokens, text) |> "
"0","  filter(!tokens %in% stop_words$word) "
"0",""
"0","# Sentiment analysis by joining the tokenized words with the AFINN lexicon"
"0","headline_sentiment_analysis <- headline_sentiment |>"
"0","  inner_join(afinn, by = c(""tokens""=""word"")) |>"
"0","  group_by(index, candidate) |>  "
"0","  summarize(sentiment = sum(value), .groups = ""drop"") |> "
"0","  inner_join(combined_index, by = c(""index"", ""candidate""))"
"0",""
"0","# aggregate at article level, total sentiment score (Positive or Negative)"
"0","headline_sentiment_analysis <- headline_sentiment_analysis|>"
"0","   group_by(index) |> "
"0","  mutate(sentiment_type = ifelse(sentiment >= 0, ""Positive"", ""Negative"")) "
"0",""
