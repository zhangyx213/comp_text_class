"0","#Tokenize the text column"
"0","vas_text <- str_replace_all(top_vas_urls$text, ""- "", """")"
"0","vas_text_df <- tibble(vas_text,)"
"0",""
"0","vas_tokenized <- vas_text_df %>%"
"0","  unnest_tokens(word,vas_text)"
"0",""
"0","#remove stop words"
"0","data(stop_words)"
"0","vas_tokenized <- vas_tokenized%>%"
"0","  anti_join(stop_words, by = c(""word"" = ""word"")) %>%"
"0","  filter(word != ""temp_file"") %>%"
"0","  filter(word != ""stories_corpus"") %>%"
"0","  filter(!grepl('[0-9]', word))"
"0",""
"0","bigrams_vas <- vas_text_df %>%"
"0","  unnest_tokens(bigrams_vas, vas_text, token=""ngrams"", n=2)"
"0",""
"0","bigrams_vas"
