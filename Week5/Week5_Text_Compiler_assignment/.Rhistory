mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
View(files)
files <- list.files("C:/Users/cathy/OneDrive/Desktop/jour689/comp_text_class/Week5/Week5_Text_Compiler_assignment/Vasectomy_reporting_raw_text", pattern="*.txt") %>%
as.data.frame() |>
rename(filename = 1) |>
#create an matching file name
mutate(index = str_replace_all(filename, ".txt", "")) %>%
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", index))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
View(files)
final_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
```
final_data |>
count(title) |>
arrange(desc(n))
```
dupe_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25))
```
dupe_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25))
dupe_data |>
count(title) |>
arrange(desc(n))
final_index <- final_data |>
inner_join(files, c("index")) |>
#you need the actual hard-coded path on this line below to the text
mutate(filepath = paste0("./Vasectomy_reporting_raw_text/", filename))
head(final_index)
files <- list.files("./Vasectomy_reporting_raw_text", pattern="*.txt") %>%
as.data.frame() |>
rename(filename = 1) |>
#create an matching file name
mutate(index = str_replace_all(filename, ".txt", "")) %>%
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", index))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
#Join the file list to the index
final_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
# Set the paths for your folders
input_folder <- "./Vasectomy_reporting_2020_2024(100)"
output_folder <- "./Vasectomy_reporting_raw_text"
# Create output folder if it doesn't exist
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Get a list of all .rtf files in the input folder
rtf_files <- list.files(path = input_folder, pattern = "\\.RTF$", full.names = TRUE)
# Convert each .rtf file to .txt
for (file in rtf_files) {
# Extract the file name without extension
file_name <- tools::file_path_sans_ext(basename(file))
# Read the RTF content
rtf_content <- read_rtf(file)
# Create output file path
output_file <- file.path(output_folder, paste0(file_name, ".txt"))
# Write the content to a .txt file
writeLines(rtf_content, output_file)
# Print progress
cat("Converted:", file, "to", output_file, "\n")
}
cat("Conversion complete!\n")
# Set the paths for your folders
input_folder <- "./Vasectomy_reporting_2020_2024(100)"
output_folder <- "./Vasectomy_reporting_raw_text"
# Create output folder if it doesn't exist
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Get a list of all .rtf files in the input folder
rtf_files <- list.files(path = input_folder, pattern = "\\.RTF$", full.names = TRUE)
# Convert each .rtf file to .txt
for (file in rtf_files) {
# Extract the file name without extension
file_name <- tools::file_path_sans_ext(basename(file))
# Read the RTF content
rtf_content <- read_rtf(file)
# Create output file path
output_file <- file.path(output_folder, paste0(file_name, ".txt"))
# Write the content to a .txt file
writeLines(rtf_content, output_file)
# Print progress
cat("Converted:", file, "to", output_file, "\n")
}
cat("Conversion complete!\n")
files <- list.files("./Vasectomy_reporting_raw_text", pattern="*.txt") %>%
as.data.frame() |>
rename(filename = 1) |>
#create an matching file name
mutate(index = str_replace_all(filename, ".txt", "")) %>%
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", index))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
final_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
final_data |>
count(title) |>
arrange(desc(n))
dupe_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25))
dupe_data |>
count(title) |>
arrange(desc(n))
final_index <- final_data |>
inner_join(files, c("index")) |>
#you need the actual hard-coded path on this line below to the text
mutate(filepath = paste0("./Vasectomy_reporting_raw_text/", filename))
head(final_index)
anti_final_index <- final_data |>
anti_join(files, c("index"))
View(dupe_data)
View(files)
View(final_data)
View(final_index)
final_index |>
count(title) |>
arrange(desc(n))
create_article_text <- function(row_value) {
#row_value is the single argument that is passed to the function
# Take each row of the dataframe
temp <- final_index %>%
slice(row_value)
# Store the filename for  use in constructing articles dataframe
temp_filename <- temp$filename
# Create a dataframe by reading in lines of a given textfile
# Add a filename column
articles_df_temp <- read_lines(temp$filepath) %>%
as_tibble() %>%
mutate(filename = temp_filename)
# Bind results to master articles_df
# <<- returns to global environment
articles_df <<- articles_df %>%
bind_rows(articles_df_temp)
}
articles_df <- tibble()
#running once to test
#create_article_text(2)
# Create an array of numbers to loop through, from 1 to the number of rows in our index dataframe
row_values <- 1:nrow(final_index)
###
# Execute function using lapply
# This loops through each row of the dataframe and append results to master file
###
lapply(row_values, create_article_text)
###
# Clean up articles_df and join to index dataframe
###
articles_df <- articles_df %>%
select(filename, sentence=value) %>%
inner_join(final_index)
write.csv(articles_df, "C:/Users/cathy/OneDrive/Desktop/jour689/comp_text_class/Week5/Week5_Text_Compiler_assignment")
write.csv(articles_df, "C:/Users/cathy/OneDrive/Desktop/jour689/comp_text_class/Week5/Week5_Text_Compiler_assignment")
write.csv(articles_df, "C:/Users/cathy/OneDrive/Desktop/jour689/comp_text_class/Week5/Week5_Text_Compiler_assignment/article_df.csv")
View(articles_df)
View(final_index)
View(anti_final_index)
View(final_index)
View(final_index)
library(tidyverse)
library(janitor)
library(rio)
library(tidytext)
vas <- rio::import("article_df.csv")
vas <- vas |>
clean_names()
vas_head <- str_replace_all(vas$hlead, "- ", "")
vas_head_df <- tibble(vas_head,)
vas_tokenized <- vas_head_df %>%
unnest_tokens(word,vas_head)
vas_tokenized
View(vas)
vas_scent <- str_replace_all(vas$sentence, "- ", "")
vas_scent_df <- tibble(vas_scent,)
vas_tokenized <- vas_scent_df %>%
unnest_tokens(word,vas_scent)
vas_tokenized
View(vas_head_df)
View(vas_head_df)
data(stop_words)
vas_tokenized <- vas_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
# Word Count
word_ct <- vas_tokenized %>%
count(word, sort=TRUE)
word_ct
bigrams <- vas_head_df %>%
unnest_tokens(bigram, vas_head, token="ngrams", n=2)
bigrams
#Filter out stop words.
bigrams1 <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams2 <- bigrams1 %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) |>
filter(!is.na(word1)) |>
filter(!is.na(word2))
# Word Count
bigram3 <- bigrams2 %>%
count(word1, word2, sort = TRUE)
bigram3
View(bigram3)
bigrams <- vas_scent_df %>%
unnest_tokens(bigram, vas_head, token="ngrams", n=2)
bigrams <- vas_scent_df %>%
unnest_tokens(bigram, vas_scent, token="ngrams", n=2)
bigrams
#Filter out stop words.
bigrams1 <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams2 <- bigrams1 %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) |>
filter(!is.na(word1)) |>
filter(!is.na(word2))
# Word Count
bigram3 <- bigrams2 %>%
count(word1, word2, sort = TRUE)
bigram3
files <- list.files("./Vasectomy_reporting_raw_text", pattern="*.txt") %>%
as.data.frame() |>
rename(filename = 1) |>
#create an matching file name
mutate(index = str_replace_all(filename, ".txt", "")) %>%
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", index))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
#Join the file list to the index
final_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
final_data |>
count(title) |>
arrange(desc(n))
dupe_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25))
dupe_data |>
count(title) |>
arrange(desc(n))
final_index <- final_data |>
inner_join(files, c("index")) |>
#you need the actual hard-coded path on this line below to the text
mutate(filepath = paste0("./Vasectomy_reporting_raw_text/", filename))
head(final_index)
anti_final_index <- final_data |>
anti_join(files, c("index"))
final_index |>
count(title) |>
arrange(desc(n))
create_article_text <- function(row_value) {
#row_value is the single argument that is passed to the function
# Take each row of the dataframe
temp <- final_index %>%
slice(row_value)
# Store the filename for  use in constructing articles dataframe
temp_filename <- temp$filename
# Create a dataframe by reading in lines of a given textfile
# Add a filename column
articles_df_temp <- read_lines(temp$filepath) %>%
as_tibble() %>%
mutate(filename = temp_filename)
# Bind results to master articles_df
# <<- returns to global environment
articles_df <<- articles_df %>%
bind_rows(articles_df_temp)
}
###
# Create elements needed to run function
###
# Create empty tibble to store results
articles_df <- tibble()
# Create an array of numbers to loop through, from 1 to the number of rows in our index dataframe
row_values <- 1:nrow(final_index)
###
# Execute function using lapply
# This loops through each row of the dataframe and append results to master file
###
lapply(row_values, create_article_text)
###
# Clean up articles_df and join to index dataframe
###
articles_df <- articles_df %>%
select(filename, sentence=value) %>%
inner_join(final_index)
library(tidyverse)
library(janitor)
library(rio)
library(tidytext)
vas <- rio::import("article_df.csv")
vas <- vas |>
clean_names()
vas_scent <- str_replace_all(vas$sentence, "- ", "")
vas_scent_df <- tibble(vas_scent,)
vas_tokenized <- vas_scent_df %>%
unnest_tokens(word,vas_scent)
vas_tokenized
data(stop_words)
vas_tokenized <- vas_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
# Word Count
word_ct <- vas_tokenized %>%
count(word, sort=TRUE)
word_ct
bigrams <- vas_scent_df %>%
unnest_tokens(bigram, vas_scent, token="ngrams", n=2)
bigrams
#Filter out stop words.
bigrams1 <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams2 <- bigrams1 %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) |>
filter(!is.na(word1)) |>
filter(!is.na(word2))
# Word Count
bigram3 <- bigrams2 %>%
count(word1, word2, sort = TRUE)
bigram3
View(vas)
---
title: "week5_text_compiler_assignment"
library(tidyverse)
library(janitor)
library(striprtf)
```
# Set the paths for your folders
input_folder <- "./Vasectomy_reporting_2020_2024(100)"
output_folder <- "./Vasectomy_reporting_raw_text"
# Create output folder if it doesn't exist
if (!dir.exists(output_folder)) {
dir.create(output_folder)
}
# Get a list of all .rtf files in the input folder
rtf_files <- list.files(path = input_folder, pattern = "\\.RTF$", full.names = TRUE)
# Convert each .rtf file to .txt
for (file in rtf_files) {
# Extract the file name without extension
file_name <- tools::file_path_sans_ext(basename(file))
# Read the RTF content
rtf_content <- read_rtf(file)
# Create output file path
output_file <- file.path(output_folder, paste0(file_name, ".txt"))
# Write the content to a .txt file
writeLines(rtf_content, output_file)
# Print progress
cat("Converted:", file, "to", output_file, "\n")
}
cat("Conversion complete!\n")
```
files <- list.files("./Vasectomy_reporting_raw_text", pattern="*.txt") %>%
as.data.frame() |>
rename(filename = 1) |>
#create an matching file name
mutate(index = str_replace_all(filename, ".txt", "")) %>%
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", index))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
final_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25)) |>
distinct(index, .keep_all = TRUE)
final_data |>
count(title) |>
arrange(desc(n))
dupe_data <- rio::import("Results list for_vasectomy, vasectomies.XLSX") |>
clean_names() |>
#create an matching file name
mutate(index = tolower(gsub("[[:punct:][:space:]|]", "", title))) |>
mutate(index = tolower(index)) |>
mutate(index = str_sub(index, 1, 25))
dupe_data |>
count(title) |>
arrange(desc(n))
final_index <- final_data |>
inner_join(files, c("index")) |>
#you need the actual hard-coded path on this line below to the text
mutate(filepath = paste0("./Vasectomy_reporting_raw_text/", filename))
head(final_index)
```
final_index |>
count(title) |>
arrange(desc(n))
create_article_text <- function(row_value) {
#row_value is the single argument that is passed to the function
# Take each row of the dataframe
temp <- final_index %>%
slice(row_value)
# Store the filename for  use in constructing articles dataframe
temp_filename <- temp$filename
# Create a dataframe by reading in lines of a given textfile
# Add a filename column
articles_df_temp <- read_lines(temp$filepath) %>%
as_tibble() %>%
mutate(filename = temp_filename)
# Bind results to master articles_df
# <<- returns to global environment
articles_df <<- articles_df %>%
bind_rows(articles_df_temp)
}
# Create empty tibble to store results
articles_df <- tibble()
# Create an array of numbers to loop through, from 1 to the number of rows in our index dataframe
row_values <- 1:nrow(final_index)
###
# Execute function using lapply
# This loops through each row of the dataframe and append results to master file
###
lapply(row_values, create_article_text)
#load tidyverse, tidytext, rio, janitor libraries
library(tidyverse)
library(janitor)
library(rio)
library(tidytext)
```
vas <- rio::import("article_df.csv")
vas <- vas |>
clean_names()
vas_scent <- str_replace_all(vas$sentence, "- ", "")
vas_scent_df <- tibble(vas_scent,)
vas_tokenized <- vas_scent_df %>%
unnest_tokens(word,vas_scent)
vas_tokenized
data(stop_words)
vas_tokenized <- vas_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
# Word Count
word_ct <- vas_tokenized %>%
count(word, sort=TRUE)
word_ct
bigrams <- vas_scent_df %>%
unnest_tokens(bigram, vas_scent, token="ngrams", n=2)
bigrams
#Filter out stop words.
bigrams1 <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams2 <- bigrams1 %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) |>
filter(!is.na(word1)) |>
filter(!is.na(word2))
# Word Count
bigram3 <- bigrams2 %>%
count(word1, word2, sort = TRUE)
bigram3
word_ct <- vas_tokenized %>%
count(word, sort=TRUE)
word_ct
data(stop_words)
vas_tokenized <- vas_tokenized %>%
anti_join(stop_words, by = c("word" = "word")) %>%
filter(word != "temp_file") %>%
filter(word != "stories_corpus") %>%
filter(!grepl('[0-9]', word))
# Word Count
word_ct <- vas_tokenized %>%
count(word, sort=TRUE)
word_ct
